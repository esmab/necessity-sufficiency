{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec7fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from random import shuffle\n",
    "from perturbation_functions import get_preds_and_scores, calc_suff, calc_necc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59671b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['orig_texts', 'necc_perturbed', 'suff_perturbed', 'necc_masks', 'suff_masks'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perts = pickle.load(open(\"Data/HateCheck_necc_suff_perturbations.pickle\",\"rb\"))\n",
    "perts['orig_texts'] = [tt.strip(' \\n') for tt in perts['orig_texts']]\n",
    "perts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd0780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "necc_masked = []\n",
    "for orig_text, necc_mask in zip(perts['orig_texts'], perts['necc_masks']):\n",
    "    orig_text = orig_text.strip().split()\n",
    "    masked = []\n",
    "    for masks in necc_mask:\n",
    "        masked.append(\" \".join(['[MASK]' if mm else tt for tt, mm in zip(orig_text, masks)]))\n",
    "    necc_masked.append(masked)\n",
    "    \n",
    "suff_masked = [] \n",
    "for orig_text, suff_mask in zip(perts['orig_texts'], perts['suff_masks']):\n",
    "    orig_text = orig_text.strip().split()\n",
    "    masked = []\n",
    "    for masks in suff_mask:\n",
    "        masked.append(\" \".join(['[MASK]' if mm else tt for tt, mm in zip(orig_text, masks)]))\n",
    "    suff_masked.append(masked)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4207f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# add special tokens for URLs, emojis and mentions (--> see pre-processing)\n",
    "special_tokens_dict = {'additional_special_tokens': ['[USER]','[EMOJI]','[URL]']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "datasets = ['CAD_abuse', \n",
    "            'Davidson_abuse', \n",
    "            'Founta_abuse',\n",
    "            'CAD_hate',\n",
    "            'Davidson_hate',\n",
    "            'Founta_hate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "necc_mask_preds = {}\n",
    "necc_mask_scores = {}\n",
    "suff_mask_preds = {}\n",
    "suff_mask_scores = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(\"Classifying HateCheck perturbations with {}.\".format(dataset))\n",
    "  #  model = BertForSequenceClassification.from_pretrained(models_dir +'BERT_{}_weighted/Final'.format(dataset))\n",
    "    model = BertForSequenceClassification.from_pretrained(\"Models/Classifiers/{}\".format(dataset))\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.eval()\n",
    "    \n",
    "    total_len = sum(len(nn) for nn in perts['necc_perturbed']) + sum(len(nn) for nn in perts['suff_perturbed'])\n",
    " \n",
    "    with tqdm(total=total_len) as pbar:\n",
    "            \n",
    "        necc_mask_preds[dataset] = []\n",
    "        necc_mask_scores[dataset] = []\n",
    "    \n",
    "        for tt in necc_masked:\n",
    "            pp, ss = get_preds_and_scores(tt, tokenizer, model, pbar)\n",
    "            necc_mask_preds[dataset].append(pp)\n",
    "            necc_mask_scores[dataset].append(ss)\n",
    "            \n",
    "        suff_mask_preds[dataset] = []\n",
    "        suff_mask_scores[dataset] = []\n",
    "    \n",
    "        for tt in suff_masked:\n",
    "            pp, ss = get_preds_and_scores(tt, tokenizer, model, pbar)\n",
    "            suff_mask_preds[dataset].append(pp)\n",
    "            suff_mask_scores[dataset].append(ss)\n",
    "            \n",
    "        \n",
    "final_results = {\n",
    "                'necc_mask_preds': necc_mask_preds,\n",
    "                'necc_mask_scores': necc_mask_scores,\n",
    "                'suff_mask_preds': suff_mask_preds,\n",
    "                'suff_mask_scores': suff_mask_scores\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c0a1331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying HateCheck instances with CAD_abuse.\n",
      "Classifying HateCheck instances with Davidson_abuse.\n",
      "Classifying HateCheck instances with Founta_abuse.\n",
      "Classifying HateCheck instances with CAD_hate.\n",
      "Classifying HateCheck instances with Davidson_hate.\n",
      "Classifying HateCheck instances with Founta_hate.\n"
     ]
    }
   ],
   "source": [
    "orig_preds = {}\n",
    "orig_scores = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(\"Classifying HateCheck instances with {}.\".format(dataset))\n",
    "  #  model = BertForSequenceClassification.from_pretrained(models_dir +'BERT_{}_weighted/Final'.format(dataset))\n",
    "    model = BertForSequenceClassification.from_pretrained(\"Models/Classifiers/{}\".format(dataset))\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.eval()\n",
    "\n",
    "    orig_preds[dataset], orig_scores[dataset] = get_preds_and_scores(perts['orig_texts'], tokenizer, model, pbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51b8b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results[\"orig_preds\"] = orig_preds\n",
    "final_results[\"orig_scores\"] = orig_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1873966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(final_results, open(\"Data/final_results_masked.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdbe93bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_preds': {'CAD_abuse': 0.0386,\n",
       "  'Davidson_abuse': 0.0728,\n",
       "  'Founta_hate': 0.0648,\n",
       "  'CAD_hate': 0.0252,\n",
       "  'Davidson_hate': 0.0238,\n",
       "  'Founta_abuse': 0.0202},\n",
       " 'baseline_scores': {'CAD_abuse': 0.04610298428169917,\n",
       "  'Davidson_abuse': 0.07315641217394732,\n",
       "  'Founta_hate': 0.07248694326588884,\n",
       "  'CAD_hate': 0.03189067478131037,\n",
       "  'Davidson_hate': 0.03256542438273318,\n",
       "  'Founta_abuse': 0.031436307859700176}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds = pickle.load(open(\"Data/Classifier_baselines.pickle\", \"rb\"))\n",
    "baseline_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa876684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "necc_results_mask = {}\n",
    "necc_results_mask_nb = {}\n",
    "suff_results_mask = {}\n",
    "suff_results_mask_nb = {}\n",
    "\n",
    "baselines = pickle.load(open(\"Data/Classifier_baselines.pickle\", \"rb\"))\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    ## NECCESSITY CALCULATIONS  \n",
    "    necc_mask = []\n",
    "    for oo, pp, mm in zip(final_results['orig_preds'][dataset], \n",
    "                          final_results['necc_mask_preds'][dataset], \n",
    "                          perts['necc_masks']):\n",
    "        pp = np.array(pp)\n",
    "        necc_mask.append(calc_necc(oo, pp, mm))\n",
    "    necc_results_mask[dataset] = necc_mask\n",
    "    \n",
    "    necc_mask_nb = []\n",
    "    for oo, pp, mm in zip(final_results['orig_scores'][dataset], \n",
    "                          final_results['necc_mask_scores'][dataset], \n",
    "                          perts['necc_masks']):\n",
    "        pp = np.array(pp)\n",
    "        necc_mask_nb.append(calc_necc(oo, pp, mm))\n",
    "    necc_results_mask_nb[dataset] = necc_mask_nb\n",
    "    \n",
    "    ## SUFFICIENCY CALCULATIONS\n",
    "    baseline_pred = baselines['baseline_preds'][dataset]\n",
    "    baseline_score = baselines['baseline_scores'][dataset]\n",
    "    \n",
    "    suff_mask = []\n",
    "    for pp, mm in zip(final_results['suff_mask_preds'][dataset], perts['suff_masks']):\n",
    "        pp = np.array(pp)\n",
    "        suff_mask.append(calc_suff(baseline_pred, pp, mm))\n",
    "    suff_results_mask[dataset] = suff_mask\n",
    "\n",
    "    suff_mask_nb = []\n",
    "    for pp, mm in zip(final_results['suff_mask_scores'][dataset], perts['suff_masks']):\n",
    "        pp = np.array(pp)\n",
    "        suff_mask_nb.append(calc_suff(baseline_score, pp, mm))\n",
    "    suff_results_mask_nb[dataset] = suff_mask_nb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91eea098",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_necc_suff_masked = {\n",
    "    'necc_results': necc_results_mask, \n",
    "    'necc_results_nb' : necc_results_mask_nb,\n",
    "    'suff_results': suff_results_mask,\n",
    "    'suff_results_nb' : suff_results_mask_nb,\n",
    "}\n",
    "\n",
    "pickle.dump(hatecheck_necc_suff_masked, open('Data/HateCheck_necc_suff_results_masked.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9dc951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
